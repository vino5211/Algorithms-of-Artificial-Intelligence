- DSSM

  - Term Vector

    - bag of words 
    - 获取所有 term : 统计所有词构建词典， 每个单词使用 one-hot 的方式表示 （500K 维度）
    - Q， D1， D2, ... , Dn 由很多单词构成 （500 K 维度）

  - Word Hasing

    - 英文：

      - 单词在 char-level 提取  tri-gram 特征 

        - #good# : #go, goo, ood, od#

      - 首先是压缩空间，50 万个词的 one-hot 向量空间可以通过 letter-trigram 压缩为一个 3 万维的向量空间。其次是增强范化能力，三个字母的表达往往能代表英文中的前缀和后缀，而前缀后缀往往具有通用的语义

      - 将 500 k 个单词以 30K tri-gram 特征项代替

        - 即 单词 的表示由 500K 维度的 one-hot 向量 表示为 30K 维度的稀疏向量

        - 问题：这样两个不同的单词会不会产出相同的tri-grams

          - paper里面做了统计，说了这个冲突的概率非常的低，500K个word可以降到30k维，冲突的概率为0.0044%

    - 中文

      - 中文的输入层处理方式与英文有很大不同，首先中文分词是个让所有 NLP 从业者头疼的事情，即便业界号称能做到 95%左右的分词准确性，但分词结果极为不可控，往往会在分词阶段引入误差。所以这里我们不分词，而是仿照英文的处理方式，对应到中文的最小粒度就是单字了。（曾经有人用偏旁部首切的，感兴趣的朋友可以试试）

        由于常用的单字为 1.5 万左右，而常用的双字大约到百万级别了，所以这里出于向量空间的考虑，采用字向量（one-hot）作为输入，向量空间约为 1.5 万维

  - 流程图

    ![](https://x-algo.cn/wp-content/uploads/2018/05/13.2.69.png)

  - 优点：

    - DSSM 用字向量作为输入既可以减少切词的依赖，又可以提高模型的范化能力，因为每个汉字所能表达的语义是可以复用的。
    - 另一方面，传统的输入层是用 Embedding 的方式（如 Word2Vec 的词向量）或者主题模型的方式（如 LDA 的主题向量）来直接做词的映射，再把各个词的向量累加或者拼接起来，由于 Word2Vec 和 LDA 都是无监督的训练，这样会给整个模型引入误差，DSSM 采用统一的有监督训练，不需要在中间过程做无监督模型的映射，因此精准度会比较高。

  - 缺点：

    - 上文提到 DSSM 采用词袋模型（BOW），因此丧失了语序信息和上下文信息
    - 另一方面，DSSM 采用弱监督、端到端的模型，预测结果不可控。

- CNN-DSSM

  - 使用上下文：

    - 英文：举个例子：把<`s`> online auto body ... <`s`>这句话提取出前三个词<`s`> online auto，之后再分别对这三个词进行letter-trigram映射到一个 3 万维的向量空间里，然后把三个向量 concat 起来，最终映射到一个 9 万维的向量空间里
    - 中文：英文的处理方式（word-trigram letter-trigram）在中文中并不可取，因为英文中虽然用了 word-ngram 把样本空间拉成了百万级，但是经过 letter-trigram 又把向量空间降到可控级别，只有 3`*`30K（9 万）。而中文如果用 word-trigram，那向量空间就是百万级的了，显然还是字向量（1.5 万维）比较可控。

  - word hash

  - 卷积+pool 提取非线性特征

    ![](https://x-algo.cn/wp-content/uploads/2018/05/13.2.70.png)

- LSTM-DSSM

  - 加入peephole

    ![](https://blog-10039692.file.myqcloud.com/1501556209287_3423_1501556210288.png)

  - 这里三条黑线就是所谓的 peephole，传统的 LSTM 中遗忘门、输入门和输出门只用了 h(t-1) 和 xt 来控制门缝的大小，peephole 的意思是说不但要考虑 h(t-1) 和 xt，也要考虑 Ct-1 和 Ct，其中遗忘门和输入门考虑了 Ct-1，而输出门考虑了 Ct。总体来说需要考虑的信息更丰富了

  - 网络结构

    ![](https://blog-10039692.file.myqcloud.com/1501556241446_432_1501556242436.png)

- DSSM类问题的缺点：

  1. DSSM 是端到端的模型，虽然省去了人工特征转化、特征工程和特征组合，但端到端的模型有个问题就是效果不可控。对于一些要保证较高的准确率的场景，用有监督人工标注的 query 分类作为打底，再结合无监督的 word2vec、LDA 等进行语义特征的向量化，显然比较可控（至少 query 分类的准确率可以达到 95%以上）。
  2. DSSM 是弱监督模型，因为引擎的点击曝光日志里 Query 和 Title 的语义信息比较弱。举个例子，搜索引擎第一页的信息往往都是 Query 的包含匹配，笔者统计过，完全的语义匹配只有不到 2%。这就意味着几乎所有的标题里都包含用户 Query 里的关键词，而仅用点击和曝光就能作为正负样例的判断？显然不太靠谱，因为大部分的用户进行点击时越靠前的点击的概率越大，而引擎的排序又是由 pCTR、CVR、CPC 等多种因素决定的。从这种非常弱的信号里提取出语义的相似性或者差别，那就需要有海量的训练样本。DSSM 论文中提到，实验的训练样本超过 1 亿。笔者和同事也亲测过，用传统 CTR 预估模型千万级的样本量来训练，模型无法收敛。可是这样海量的训练样本，恐怕只有搜索引擎才有吧？普通的搜索业务 query 有上千万，可资源顶多只有几百万，像论文中说需要挑出点击和曝光置信度比较高且资源热度也比较高的作为训练样本，这样就过滤了 80%的长尾 query 和 Title 结果对，所以也只有搜索引擎才有这样的训练语料了吧。另一方面，超过 1 亿的训练样本作为输入，用深度学习模型做训练，需要大型的 GPU 集群，这个对于很多业务来说也是不具备的条件。