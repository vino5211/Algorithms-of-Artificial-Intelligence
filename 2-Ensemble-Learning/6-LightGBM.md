# LightGBM：
### 优化
+ 采用基于Histogram的决策树算法 把每个特征做转化成int，并用这个int作为直方图的index，如果某一个特征值的值为ki，就在直方图横轴=ki的地方，增加1的高度 最后根据直方图进行分裂 带来的好处：
	1. 不用计算分裂增益
	2. 只消耗很少的内存，解决xgboost为了排序需要把特征都加进内存需要巨大的空间
+ 带深度限制的Leaf-wise的叶子生长策略。 直接找到分裂增益最大的叶子，按层优先不断分裂
	1. 提高精度降低误差
	2. 减少Level-wise非常非常的无用叶子的分裂
	3. 因为特征的访问顺序相同，就可以提高cache优化，意味着CPU可以为下一次会采用的特征预先做预读取
+ 用histogram 做差加速 一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到 也就是说下一次分裂的时候不需要计算分裂增益，直接计算一个大儿子，另一个小儿子的直方图就是父亲减去大儿子的差 1.进一步优化