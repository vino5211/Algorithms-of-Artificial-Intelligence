# Gradient Boosting

## Key
+ 回归模型，要量化上一个模型的指标，在残差的基础上拟合下一颗树（以GBDT为例）
+ demo
“”“
有一个样本[数据->标签]是：[(2，4，5)-> 4]
第一棵决策树用这个样本训练的预测为3.3
那么第二棵决策树训练时的输入，这个样本就变成了：[(2，4，5)-> 0.7]
也就是说，下一棵决策树输入样本会与前面决策树的训练和预测相关
”“”

+ 更一般的boosting
+ ![](https://pic4.zhimg.com/80/v2-c75f66da84db9f86f4191903d1d156d9_hd.jpg)
+ 每一次建立模型是在之前建立模型损失函数的梯度下降方向