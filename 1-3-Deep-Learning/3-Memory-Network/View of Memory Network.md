# Summary
## Reference
+ https://blog.csdn.net/irving_zhang/article/details/79094416
## Facebook AI：
+ 2015年提出MEMORY NETWORKS,使用记忆网络增强记忆。（引用数：475）
+ 2015年提出End-To-End Memory Networks，针对上一篇文章中存在的无法端到端训练的问题，提出了端到端的记忆网络。（引用数：467）
+ 2016年提出Key-Value Memory Networks for Directly Reading Documents，在端到端的基础上增加记忆的规模。（引用数：68）
+ 2017年提出TRACKING THE WORLD STATE WITH RECURRENT ENTITY NETWORKS，论文提出了一种新的动态记忆网络，其使用固定长度的记忆单元来存储世界上的实体，每个记忆单元对应一个实体，主要存储该实体相关的属性（譬如一个人拿了什么东西，在哪里，跟谁等等信息），且该记忆会随着输入内容实时更新。（引用数：27）

## Google DeepMind:
+ 2014年提出Neural Turing Machines，神经图灵机，同facebook团队的记忆网络一样，是开篇之作。（引用数：517）
+ 2015年提出Neural Random Access Machines,神经网络随机存取机。（引用数：55）
+ 2015年提出Learning to Transduce with Unbounded Memory,使用诸如栈或（双端）队列结构的连续版本。（引用数：99）
+ 2016年提出Neural GPUs Learn Algorithms,神经网络GPU,使用了带有读写磁头的磁带。（引用数：86）